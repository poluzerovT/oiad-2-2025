
# ОИАД. Теория к лабораторной №2

## Корреляция Фехнера

Рассматриваются знаки отклонений наблюдений от среднего $sign(x_i - \overline{x})$ и $sign(y_i - \overline{y})$.

При расчёте корреляции вычисляется число совпадающих знакоков минус число не совпадающих.

$$
K = \frac{
    \sum_{i=1}^{n} 
    [sign(x_i - \overline{x}) = sign(y_i - \overline{y})] - 
    [sign(x_i - \overline{x}) \ne sign(y_i - \overline{y})]
    }{n}
$$
Здесь оператор $[ * ]$ принимает значения: $[True] = 1, [False] = 0$.

*Какая область значений у коэффициента корреляции?*

## Корреляция Пирсона

Корреляция Пирсона учитывает не только знаки отклонений, но и абсолютные значения отклонений от среднего значения.

Ковариация определяется как среднее произведение отклонений значений двух признаков от их средних значений. 

$$
    cov = \frac{
        \sum_{i=1}^{n}
            (x_i - \overline{x}) (y_i - \overline{y}) 
    }{n-1}
$$
Для приведения значений в интервал $[-1, 1]$, ковариацию делят на проивзедение стандартных отклонений признаков.
$$
    K = \frac{cov}{S_x S_y}
$$

где $S_x^2$ - выборочная дисперсия,
$$
    S_x^2 = \frac{\sum_{i=1}^{n} (x - \overline{x})^2}{n-1}
$$

**Значимость корреляции Пирсона**
$H0$: Переменные $x$ и $y$ - некоррелированы, т.е. $K = 0$

При справедливости $H0$, статистика
$$
T = \frac{K \sqrt{n-2}}{\sqrt{1-K^2}} 
$$
имеет распределение:
* при $n < 30$, распределение Стьюдента $T \sim t_{n-2}$
* при $n \ge 30$, стандартное нормальное распределени (*почему?*) 
  
*Какая критическая область критерия?*
## Корреляция Спирмена

Рангом $i$-го элемента выборки $x_i$ называется его порядковый номер $R(x_i)$ в упорядоченном ряду (вариационном ряду).

Корреляция Спирмана есть корреляция Пирсона над ранговыми наборами $(R(x_1)_, \dots, R(x_1))$ и $(R(y_1)_, \dots, R(y_1))$

$$
K = \frac{
    \sum_{i=1}^{n} 
    (R(x_i) - \overline{R(x)}) \cdot (R(y_i) - \overline{R(y)}) 
    }
    {
        \left[
        \left( \sum_{i=1}^{n} (R(x_i) - \overline{R(x)})^2 \right)
        \cdot
        \left( \sum_{i=1}^{n} (R(y_i) - \overline{R(y)})^2 \right)
        \right]^{\frac{1}{2}}
    } =
$$
$$
= 1 - \frac{6}{n (n-1) (n+1)} \sum_{i=1}^{n} \left( R(x_i) - R(y_i)\right)^2
$$

## Корреляция Кенделла

$$
K = 1 - \frac{4}{n (n-1)} 
\sum_{i=1}^{n-1} \sum_{j=i+1}^{n}
\left[ [x_i < x_j] \ne [y_i < y_j] \right]
$$

## Метод наименьших квадратов

Попробуем по выборочным данным восстановить вид зависимости $y$ от $x$.
Такая задача называется задачей регрессии.
В качестве регрессионной модели выберем, например, класс линейных фукнций (линейных по параметрам, модель $\hat{y}(x, w) = w_1 \ln x + w_0$ попрежнему линейная). 
$$
\hat{y}(x, w) = w_1 x + w_0
$$

Параметры $w$ будем подбирать для наилучшего соотвествия нашей регрессионной модели истинным выборочным данных. Рассмотрим сумарный квадрат ошибок нашей модели
$$
Q(w) = \sum_{i=1}^{n} (y_i - \hat{y}(x_i, w))^2 \rightarrow \min_{w}
$$

Оптимизационная задача решается:
* аналитически (не всегда можно найти) через необходимое условие минимума
$$
\frac{\partial{Q}}{\partial{w}} = 0
$$
*найдите аналитическое решение для линейной модели сами*
* численно, используя градиентные методы

Минимальная ошибка достигается на при значениях параметров $w*$
$$
w^* = \argmin Q(w)
$$

Тогда наша регрессионная модель имеет вид
$$
\hat{y}(x) = w_1^* x + w_0^*
$$


## Значимость уравнения регрессии
Для регрессионной модели определяется коэффициент детерминации
$$
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \overline{y}_i)^2}
$$
Числитель $\sum_{i=1}^{n} (y_i - \hat{y}_i)^2$ показывает сумарные квадраты ошибок при использовании модели, а знаменатель $\sum_{i=1}^{n} (y_i - \overline{y}_i)^2$ - при использовании среднего в качестве прогнозного значения. Коэффициент детерминации отражает улучшается ли качество прогнозирования используя регрессионную модель, по сравнению с предсказанием средним.

$H0:$ уравнение регрессии не значимо, $w=0$

При справедливости $H0$, статистика 
$$
F = \frac{R^2}{1-R^2} \cdot \frac{n-k}{k-1}
$$
имеет распределение Фишера $F(k-1, n-k)$, где $k$ - число параметров модели
*Какая критическая область критерия?*

## Нелинейные модели регрессии

Некоторые нелинейные регрессионные модели можно свести к линейным используя нелинейные преобразования и замену переменных. Наример:

1. $ y = a e^{bx} \rightarrow \ln y = bx + \ln a \rightarrow y' = bx + a'$
2. $ y = \frac{a}{x + c} + b \rightarrow \frac{1}{y-b}= \frac{x}{a} + \frac{c}{a} \rightarrow y' = a'x + c'$
